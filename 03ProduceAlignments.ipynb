{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignments \n",
    "Based on the results \"Align Experiments.ipynb\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n",
      "en\n",
      "fr\n",
      "ar\n",
      "ru\n",
      "uk\n",
      "pt\n",
      "vi\n",
      "zh\n",
      "ru\n",
      "he\n",
      "it\n",
      "ta\n",
      "id\n",
      "fa\n",
      "ca\n"
     ]
    }
   ],
   "source": [
    "#Load dependencies\n",
    "import networkx as nx\n",
    "import json\n",
    "import numpy as np\n",
    "import fastText\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "\n",
    "#Define supported languages \n",
    "#langs = ['es','en']#,'ru'] #,'ca']\n",
    "with open('config.json') as f:\n",
    "    langs = json.load(f)['langs']\n",
    "\n",
    "#Load models & transformations \n",
    "models = {}\n",
    "transmat = {}\n",
    "for lang in langs:\n",
    "    print(lang)\n",
    "    transmat[lang] = {}\n",
    "    for lang2 in langs:\n",
    "        if lang!=lang2:\n",
    "            transmat[lang][lang2] = np.loadtxt('my_alingments/apply_in_%s_to_%s.txt' % (lang2,lang))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "import requests\n",
    "import json\n",
    "import mwparserfromhell\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "        \n",
    "def getWikidataPair(titles,lang,target):\n",
    "    \"\"\"\n",
    "    titles: list of pages titles\n",
    "    lang:source lang (same of the titles)\n",
    "    target: target lang\n",
    "    returns a list: page_title_source,page_title_target\n",
    "    \"\"\"\n",
    "    wikidataInfo =  []\n",
    "    for tchunks in chunks(titles,50): #requests can have max 50 titles\n",
    "        response= requests.get(\"https://www.wikidata.org/w/api.php?action=wbgetentities&sites=%swiki&titles=%s&props=sitelinks&format=json\" % (lang,'|'.join(tchunks)))\n",
    "        try:\n",
    "            result = list(response.json()['entities'].items())\n",
    "            if result:\n",
    "                wikidataInfo.extend(result)\n",
    "        except:\n",
    "            pass\n",
    "        sleep(0.5)\n",
    "    output = []\n",
    "    for entity,data in  wikidataInfo:\n",
    "        if 'sitelinks' in data:\n",
    "            if data['sitelinks'].get(target+'wiki'):\n",
    "                s=data['sitelinks'][lang+'wiki']['title']\n",
    "                t=data['sitelinks'][target+'wiki']['title']\n",
    "                output.append([s,t])\n",
    "    return output\n",
    "\n",
    "def getWikidataID(titles,lang):\n",
    "    \"\"\"\n",
    "    titles: list of pages titles\n",
    "    lang:source lang (same of the titles)\n",
    "    target: target lang\n",
    "    returns a list: page_title_source,page_title_target\n",
    "    \"\"\"\n",
    "    response= requests.get(\"https://www.wikidata.org/w/api.php?action=wbgetentities&sites=%swiki&titles=%s&props=sitelinks&format=json\" % (lang,'|'.join(titles)))\n",
    "    results = response.json()['entities'].items()\n",
    "    output = []\n",
    "    \n",
    "    for entity,data in  response.json()['entities'].items():\n",
    "        if data['sitelinks'].get(target+'wiki'):\n",
    "            s=data['sitelinks'][lang+'wiki']['title']\n",
    "            t=data['sitelinks'][target+'wiki']['title']\n",
    "            output.append([s,t])\n",
    "    return output\n",
    "\n",
    "\n",
    "#Get articles\n",
    "def getContent(title,lang):\n",
    "    \"\"\"\n",
    "    title: page title\n",
    "    lang: lang\n",
    "    returns wikitext\n",
    "    \"\"\"\n",
    "    url = \"https://%s.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&format=json&formatversion=2&titles=%s\" % (lang,title)\n",
    "    response = requests.get(url)\n",
    "    content = response.json()['query']['pages'][0]['revisions'][0]['content']\n",
    "    return content\n",
    "\n",
    "#get all the templates with named parameters\n",
    "def extract_templates(text):\n",
    "    wikicode = mwparserfromhell.parse(text)\n",
    "    tmpdict = {}\n",
    "    for template in wikicode.filter_templates():\n",
    "        if template.params:\n",
    "            values = dict([[t.name.strip(),t.value.strip()] for t in template.params if t.showkey])\n",
    "            if values:\n",
    "                tmpdict[template.name.strip()] = values\n",
    "    return tmpdict\n",
    "\n",
    "def getTemplateData(template,lang):\n",
    "    url =  \"https://%s.wikipedia.org/w/api.php?action=templatedata&titles=%s&formatversion=2&redirects=1\" % (lang,template)\n",
    "    #print(url)\n",
    "    resp = requests.get(url)\n",
    "    data = list(resp.json()['pages'].values())[0]\n",
    "    return data\n",
    "\n",
    "\n",
    "def apply_transform(vec, transform):\n",
    "        \"\"\"\n",
    "        Apply the given transformation to the vector space\n",
    "\n",
    "        Right-multiplies given transform with embeddings E:\n",
    "            E = E * transform\n",
    "\n",
    "        Transform can either be a string with a filename to a\n",
    "        text file containing a ndarray (compat. with np.loadtxt)\n",
    "        or a numpy ndarray.\n",
    "        \"\"\"\n",
    "        transmat = np.loadtxt(transform) if isinstance(transform, str) else transform\n",
    "        return np.matmul(vec, transmat)\n",
    "    \n",
    "def getWikidataPairMultiLangs(titles,lang,targets):\n",
    "    \"\"\"\n",
    "    titles: list of pages titles\n",
    "    lang:source lang (same of the titles)\n",
    "    target: liist, target langs\n",
    "    returns a list: page_title_source,page_title_target\n",
    "    \"\"\"\n",
    "    wikidataInfo =  []\n",
    "    c = 0\n",
    "    print('Loading templates names in %s' % lang)\n",
    "    for tchunks in chunks(titles,50): #requests can have max 50 titles\n",
    "        c+=len(tchunks)\n",
    "        print(int(100*c/len(titles)),'%', end=' - ')\n",
    "        response= requests.get(\"https://www.wikidata.org/w/api.php?action=wbgetentities&sites=%swiki&titles=%s&props=sitelinks&format=json\" % (lang,'|'.join(tchunks)))\n",
    "        try:\n",
    "            result = list(response.json()['entities'].items())\n",
    "            if result:\n",
    "                wikidataInfo.extend(result)\n",
    "        except:\n",
    "            pass\n",
    "        sleep(0.5)\n",
    "    output = []\n",
    "    for entity,data in  wikidataInfo:\n",
    "        outlangs = {}\n",
    "        if 'sitelinks' in data:\n",
    "            for target in targets:\n",
    "                if data['sitelinks'].get(target+'wiki'):\n",
    "                    s=data['sitelinks'][lang+'wiki']['title']\n",
    "                    t=data['sitelinks'][target+'wiki']['title']\n",
    "                    outlangs[target]  = t\n",
    "            output.append([s,outlangs])\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get templates prefix (exs: Template:, Plantilla:)\n",
    "#I use cite Web, because it exists in all the targeted languages\n",
    "prefixes = {}\n",
    "for lang in langs:\n",
    "    pairsTemplate = getWikidataPair(['Template:Cite web'],'en',lang)\n",
    "    prefixes[lang] = pairsTemplate[0][1].split(':')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignSets(set1,set2,sourceLang,targetLang):\n",
    "    \"\"\"\n",
    "    Given two sets of words/sentences in two languages\n",
    "    return the possible alignments between sentences\n",
    "    set1: dict or list, ['hola','perro']\n",
    "    set2: dict or list, ['hello','dog']\n",
    "    sourceLang: str, 'es'\n",
    "    targetLang: str, 'en'\n",
    "    return list\n",
    "    \"\"\"\n",
    "    global models\n",
    "    global transmat\n",
    "    output = []\n",
    "    G= nx.Graph()\n",
    "    for s1 in set1:\n",
    "        vec1 = models[sourceLang].get_sentence_vector(s1.strip().replace('_',' '))\n",
    "        for s2 in set2:\n",
    "                    vec2= models[targetLang].get_sentence_vector(s2.strip().replace('_',' '))\n",
    "                    vec2T = apply_transform(vec2,transmat[sourceLang][targetLang])\n",
    "                    dist = distance.cosine(vec1,vec2T)\n",
    "                    if dist < .45:\n",
    "                        node1= '%s_%s' % (sourceLang,s1)\n",
    "                        node2= '%s_%s' % (targetLang,s2)\n",
    "                        G.add_edge(node1,node2)\n",
    "                        G[node1][node2]['w'] = dist\n",
    "\n",
    "                \n",
    "    while G.edges():\n",
    "            p = sorted(G.edges(data=True), key=lambda x: x[2]['w'])[0]\n",
    "            psorted = sorted(list(p[:2]))\n",
    "            output.append({psorted[0][:2]:psorted[0][3:],psorted[1][:2]:psorted[1][3:],'d':p[2]['w']})\n",
    "            #print(psorted[0][3:],'->',psorted[1][3:])\n",
    "\n",
    "            G.remove_node(p[0])\n",
    "            G.remove_node(p[1])\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n",
      "Loading templates names in es\n",
      "3 % - 6 % - 10 % - 13 % - 17 % - 20 % - 23 % - 27 % - 30 % - 34 % - 37 % - 40 % - 44 % - 47 % - 51 % - 54 % - 58 % - 61 % - 64 % - 68 % - 71 % - 75 % - 78 % - 81 % - 85 % - 88 % - 92 % - 95 % - 98 % - 100 % - \n",
      "== en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/dsaez/3.6/lib/python3.5/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "en\n",
      "Loading templates names in en\n",
      "0 % - 0 % - 0 % - 0 % - 1 % - 1 % - 1 % - 1 % - 2 % - 2 % - 2 % - 2 % - 3 % - 3 % - 3 % - 3 % - 4 % - 4 % - 4 % - 4 % - 5 % - 5 % - 5 % - 5 % - 6 % - 6 % - 6 % - 6 % - 7 % - 7 % - 7 % - 7 % - 8 % - 8 % - 8 % - 8 % - 9 % - 9 % - 9 % - 9 % - 10 % - 10 % - 10 % - 10 % - 11 % - 11 % - 11 % - 11 % - 12 % - 12 % - 12 % - 12 % - 13 % - 13 % - 13 % - 13 % - 14 % - 14 % - 14 % - 14 % - 15 % - 15 % - 15 % - 15 % - 16 % - 16 % - 16 % - 16 % - 17 % - 17 % - 17 % - 17 % - 18 % - 18 % - 18 % - 18 % - 19 % - 19 % - 19 % - 19 % - 20 % - 20 % - 20 % - 20 % - 20 % - 21 % - 21 % - 21 % - 21 % - 22 % - 22 % - 22 % - 22 % - 23 % - 23 % - 23 % - 23 % - 24 % - 24 % - 24 % - 24 % - 25 % - 25 % - 25 % - 25 % - 26 % - 26 % - 26 % - 26 % - 27 % - 27 % - 27 % - 27 % - 28 % - 28 % - 28 % - 28 % - 29 % - 29 % - 29 % - 29 % - 30 % - 30 % - 30 % - 30 % - 31 % - 31 % - 31 % - 31 % - 32 % - 32 % - 32 % - 32 % - 33 % - 33 % - 33 % - 33 % - 34 % - 34 % - 34 % - 34 % - 35 % - 35 % - 35 % - 35 % - 36 % - 36 % - 36 % - 36 % - 37 % - 37 % - 37 % - 37 % - 38 % - 38 % - 38 % - 38 % - 39 % - 39 % - 39 % - 39 % - 40 % - 40 % - 40 % - 40 % - 41 % - 41 % - 41 % - 41 % - 41 % - 42 % - 42 % - 42 % - 42 % - 43 % - 43 % - 43 % - 43 % - 44 % - 44 % - 44 % - 44 % - 45 % - 45 % - 45 % - 45 % - 46 % - 46 % - 46 % - 46 % - 47 % - 47 % - 47 % - 47 % - 48 % - 48 % - 48 % - 48 % - 49 % - 49 % - 49 % - 49 % - 50 % - 50 % - 50 % - 50 % - 51 % - 51 % - 51 % - 51 % - 52 % - 52 % - 52 % - 52 % - 53 % - 53 % - 53 % - 53 % - 54 % - 54 % - 54 % - 54 % - 55 % - 55 % - 55 % - 55 % - 56 % - 56 % - 56 % - 56 % - 57 % - 57 % - 57 % - 57 % - 58 % - 58 % - 58 % - 58 % - 59 % - 59 % - 59 % - 59 % - 60 % - 60 % - 60 % - 60 % - 61 % - 61 % - 61 % - 61 % - 62 % - 62 % - 62 % - 62 % - 62 % - 63 % - 63 % - 63 % - 63 % - 64 % - 64 % - 64 % - 64 % - 65 % - 65 % - 65 % - 65 % - 66 % - 66 % - 66 % - 66 % - 67 % - 67 % - 67 % - 67 % - 68 % - 68 % - 68 % - 68 % - 69 % - 69 % - 69 % - 69 % - 70 % - 70 % - 70 % - 70 % - 71 % - 71 % - 71 % - 71 % - 72 % - 72 % - 72 % - 72 % - 73 % - 73 % - 73 % - 73 % - 74 % - 74 % - 74 % - 74 % - 75 % - 75 % - 75 % - 75 % - 76 % - 76 % - 76 % - 76 % - 77 % - 77 % - 77 % - 77 % - 78 % - 78 % - 78 % - 78 % - 79 % - 79 % - 79 % - 79 % - 80 % - 80 % - 80 % - 80 % - 81 % - 81 % - 81 % - 81 % - 82 % - 82 % - 82 % - 82 % - 83 % - 83 % - 83 % - 83 % - 83 % - 84 % - 84 % - 84 % - 84 % - 85 % - 85 % - 85 % - 85 % - 86 % - 86 % - 86 % - 86 % - 87 % - 87 % - 87 % - 87 % - 88 % - 88 % - 88 % - 88 % - 89 % - 89 % - 89 % - 89 % - 90 % - 90 % - 90 % - 90 % - 91 % - 91 % - 91 % - 91 % - 92 % - 92 % - 92 % - 92 % - 93 % - 93 % - 93 % - 93 % - 94 % - 94 % - 94 % - 94 % - 95 % - 95 % - 95 % - 95 % - 96 % - 96 % - 96 % - 96 % - 97 % - 97 % - 97 % - 97 % - 98 % - 98 % - 98 % - 98 % - 99 % - 99 % - 99 % - 99 % - 100 % - \n",
      "== es\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "fr\n",
      "Loading templates names in fr\n",
      "2 % - 5 % - 7 % - 10 % - 13 % - 15 % - 18 % - 21 % - 23 % - 26 % - 29 % - 31 % - 34 % - 37 % - 39 % - 42 % - 45 % - 47 % - 50 % - 53 % - 55 % - 58 % - 61 % - 63 % - 66 % - 69 % - 71 % - 74 % - 77 % - 79 % - 82 % - 85 % - 87 % - 90 % - 93 % - 95 % - 98 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "ar\n",
      "Loading templates names in ar\n",
      "6 % - 13 % - 19 % - 26 % - 33 % - 39 % - 46 % - 52 % - 59 % - 66 % - 72 % - 79 % - 86 % - 92 % - 99 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "ru\n",
      "Loading templates names in ru\n",
      "3 % - 6 % - 9 % - 12 % - 15 % - 18 % - 21 % - 24 % - 27 % - 30 % - 33 % - 37 % - 40 % - 43 % - 46 % - 49 % - 52 % - 55 % - 58 % - 61 % - 64 % - 67 % - 70 % - 74 % - 77 % - 80 % - 83 % - 86 % - 89 % - 92 % - 95 % - 98 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "uk\n",
      "Loading templates names in uk\n",
      "5 % - 10 % - 15 % - 20 % - 26 % - 31 % - 36 % - 41 % - 47 % - 52 % - 57 % - 62 % - 68 % - 73 % - 78 % - 83 % - 89 % - 94 % - 99 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "pt\n",
      "Loading templates names in pt\n",
      "3 % - 7 % - 11 % - 14 % - 18 % - 22 % - 26 % - 29 % - 33 % - 37 % - 41 % - 44 % - 48 % - 52 % - 56 % - 59 % - 63 % - 67 % - 71 % - 74 % - 78 % - 82 % - 86 % - 89 % - 93 % - 97 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "vi\n",
      "Loading templates names in vi\n",
      "6 % - 13 % - 20 % - 26 % - 33 % - 40 % - 46 % - 53 % - 60 % - 66 % - 73 % - 80 % - 86 % - 93 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "zh\n",
      "Loading templates names in zh\n",
      "3 % - 7 % - 10 % - 14 % - 17 % - 21 % - 24 % - 28 % - 31 % - 35 % - 38 % - 42 % - 45 % - 49 % - 53 % - 56 % - 60 % - 63 % - 67 % - 70 % - 74 % - 77 % - 81 % - 84 % - 88 % - 91 % - 95 % - 98 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "ru\n",
      "Loading templates names in ru\n",
      "3 % - 6 % - 9 % - 12 % - 15 % - 18 % - 21 % - 24 % - 27 % - 30 % - 33 % - 37 % - 40 % - 43 % - 46 % - 49 % - 52 % - 55 % - 58 % - 61 % - 64 % - 67 % - 70 % - 74 % - 77 % - 80 % - 83 % - 86 % - 89 % - 92 % - 95 % - 98 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "he\n",
      "Loading templates names in he\n",
      "14 % - 28 % - 42 % - 56 % - 70 % - 84 % - 98 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "it\n",
      "Loading templates names in it\n",
      "6 % - 12 % - 19 % - 25 % - 31 % - 38 % - 44 % - 51 % - 57 % - 63 % - 70 % - 76 % - 82 % - 89 % - 95 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== ta\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "ta\n",
      "Loading templates names in ta\n",
      "21 % - 42 % - 64 % - 85 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== id\n",
      "== fa\n",
      "== ca\n",
      "id\n",
      "Loading templates names in id\n",
      "6 % - 13 % - 19 % - 26 % - 32 % - 39 % - 46 % - 52 % - 59 % - 65 % - 72 % - 79 % - 85 % - 92 % - 98 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== fa\n",
      "== ca\n",
      "fa\n",
      "Loading templates names in fa\n",
      "6 % - 13 % - 19 % - 26 % - 32 % - 39 % - 46 % - 52 % - 59 % - 65 % - 72 % - 79 % - 85 % - 92 % - 98 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== ca\n",
      "ca\n",
      "Loading templates names in ca\n",
      "4 % - 8 % - 12 % - 16 % - 20 % - 24 % - 28 % - 32 % - 37 % - 41 % - 45 % - 49 % - 53 % - 57 % - 61 % - 65 % - 70 % - 74 % - 78 % - 82 % - 86 % - 90 % - 94 % - 98 % - 100 % - \n",
      "== es\n",
      "== en\n",
      "== fr\n",
      "== ar\n",
      "== ru\n",
      "== uk\n",
      "== pt\n",
      "== vi\n",
      "== zh\n",
      "== ru\n",
      "== he\n",
      "== it\n",
      "== ta\n",
      "== id\n",
      "== fa\n"
     ]
    }
   ],
   "source": [
    "for lang1 in langs:\n",
    "    print(lang1)\n",
    "    with open('templates-summary_%s.json' % lang1) as f:\n",
    "        templates1 = json.load(f)\n",
    "    templates1Popular = dict([ (name,data)for name,data in templates1.items() if data['Tcount'] >50 ])\n",
    "    pairs = getWikidataPairMultiLangs(['%s:%s' % (prefixes[lang1],templateName) for  templateName in templates1Popular.keys()],lang1,langs) \n",
    "    models = {}\n",
    "    models[lang1] = fastText.load_model('vectors/wiki.%s.bin' % lang1)  \n",
    "    print()\n",
    "    for lang2 in langs:\n",
    "        output = {}\n",
    "        if lang1 != lang2:\n",
    "            print('== %s' % lang2)\n",
    "            models[lang2] = fastText.load_model('vectors/wiki.%s.bin' % lang2)  \n",
    "            with open('templates-summary_%s.json' % lang2) as f:\n",
    "                templates2 = json.load(f)\n",
    "            for t1,t2 in pairs:\n",
    "                if lang2 in t2:\n",
    "                    t2 = t2[lang2]\n",
    "                    try:\n",
    "                        template1 = templates1[t1.split(':')[1]]\n",
    "                        template2 = templates2[t2.split(':')[1]]\n",
    "                        template1['params'] = [x[0] for x in template1['Params'].items() if x[1]/len(template1['Params']) > .3] #appears at least X% of times\n",
    "                        template2['params'] = [x[0] for x in template2['Params'].items() if x[1]/len(template2['Params']) > .05] #appears at least 1X of times\n",
    "                        alignments = alignSets(template1['params'],template2['params'],lang1,lang2)\n",
    "                        output[t1] = alignments\n",
    "                    except: \n",
    "                        pass\n",
    "            with open('templatesAligned/templatesAligned_from_%s_to_%s.json' % (lang1,lang2),'w') as f:\n",
    "                json.dump(output,f)\n",
    "            del(models[lang2]) #free memory\n",
    "    del(models)#free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
